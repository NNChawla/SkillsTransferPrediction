Have experimented across the following parameters:
- Segment size (full sequence or 1 second intervals)
- Enabled trackers (Head, Left Hand, Right Hand)
- Enabled measurements (combinations of position, euler, quat, sixD)
- Enabled metadata (combinations of build time and gender)
- Handle NaN (impute or drop)
- Train set (A or B)
- Sample rate (None or 20 seconds)

Predicting:
- Regression (raw score): RMSE, MAE, R2, MSE
- Classification (category): Accuracy, F1-Score, Precision, Recall

Version 1 (v1)
Parallelized both regression and classification experiments. ~5-6 minutes per ~800-900 experiments.
Testing with full segment size only, imputing NaN values only, and no sample rate (using full sequence).

Findings:
In both classification and regression, the left hand seems to be the key tracker. I think some combination of build time and the rotation representations could be helpful as well; can't tell yet.
Better results testing on A when training on B, not by a lot but makes sense given users completed A before B.
Scores for both are very low, there are a lot of potential reasons for this.
- Only using kNNs, could explore GBMs, Random Forests, SVMs for classification.
- Need to verify that the data is being normalized and scaled without issues.
- Not tuning the hyperparameters at all, could be helpful.
- Feature engineering could be useful, lot of potential features to be examined.

Thoughts:
- Consider the relationship between the features; how linear are they, does it make sense that one model would be better than another?
- Can probably automate the feature combination process, rather than manually specifying them.
- Using a config file for the experiment parameters would be helpful.
    - Specifying models, metrics, etc.
    - Feature combinations should be generated based on the ones specified in the config file.
- Generating some visuals for the results would be helpful.
- Can probably use a single approach for both regression and classification, rather than two separate ones.
    - Just need to use classes to separate the two, and then use a single pipeline for the experiments.
    - Need to make the pipeline flexible, more modular, including the ability to add new models, metrics, etc.

Docket:
1. Separate feature specification to config file
2. Automatically generate all feature combinations in config file, keeping x, y, and z components together for features like position and euler.
3. Unify classification and regression experiments into a single pipeline, using classes to separate the two.
4. Make the pipeline flexible, more modular, including the ability to add new models, metrics, etc.
5. Update the architecture so that derived/engineered features can easily be added to the pipeline and specified in the config file.
6. Engineer kinematic and motion features
7. Add new derived features to config file rerun experiments for v2

Version 2 (v2)
Testing with train policy A only, segment size full, sample rate null, and no metadata.
Beginning with position, quat, velocity, and angular velocity.
My logic is that the metadata has not had a significant effect so far, and it seems as if (and makes sense that) good performance training on A will indicate good performance on B.
Was running out of RAM due to large size of each csv as number of features increases (30mb per file). Need to optimize loading, considering converting CSVs to Parquets.

Key Finding: Memory isn't the issue; number of combinations is just exponentially crazy. Improved speed; roughly 3 experiments per second now.
Key Finding: future direction is to better understand the feature space. Postpone engineering until pipeline to better understand existing features is established.

Backup to github
Need to load the data in and then export the combined dataframe to a single file for analysis.
Need a separate script where feature distribution and correlation (VIF and correlation matrix) can be investigated.
Full EDA (check chatgpt logs) pipeline, looking at data from start to finish.
Train a random forest on all variables and explore the SHAP values.

LightGBM
Scene-Relative Thoughts
Best performance so far (-0.506) with Left Hand angular velocity only.
Tested other individual variables, but performance was worse.
Improvement in performance is significant when dropping the head vs hand trackers.
General thoughts are:
    - Position and rotation may be largely redundant for this model at least.
    - Head Tracker seems to be contributing noise, but not sure what particular signal.
    - Angular Velocity seems more informative than linear velocity.

Body-Relative Thoughts
So big surprise, the pause duration features and gender yield the best performance so far?
Using a feature by itself yields the best performance so far I think.
Unsure of how much the use of all summary statistics is contributing to this.
Body relative transformation does not seem to yield better performance, barely worse but not worth the effort then.
Maybe not strictly the case though; Left hand body relative time since pause yields 0.365, which ~5% better than scene relative.
Right hand pause duration yields the best performance so far (-0.317).
Head signals seem largely noisey.
Pairing gender with right hand pause duration actually yields better performance (-0.309).
Why would body relative pause duration/time since pause not do as well when paired with gender?
Still need to look at X, Y, and Z components of all the motion features individually. Waiting till v3 to adjust summary statistics.

Need to test with kNN and random forest, but going to wait till v3.

V3 docket:
    - Need to update config and scripts to remove tracker and measurement combinations, switch all to global features.
    - All features (metadata, global) should be able to specify which summary statistics to use.
    - Acceleration and jerk features should be added, to see if even further improvement can be had, since velocity was better than position.
    - Need to be able to specify what features to remain constant in combinations
    - Need to be able to specify what combination sizes to use
    - Need to separate out motion feature x,y,z components; each should be an individual feature so they can be studied and summary stats can be varied appropriately.

Version 3 (v3)

Conducting a test with all features, but only using one combination size.
Going for a greedy approach, starting with the most important features and then adding more as needed.
Tested MLP, SVM, Random Forest, LightGBM, and KNN on combination size 1.
Got first -0.2* and -0.1* R^2 scores!
-0.2* scores are from MLP, lgbm, and knn.
-0.1* score is from knn (right hand velocity x mean).
Seems like the top features are right hand velocity x mean, gender, pause duration. Angular and Linear velocity are meaningful.
Need to add acceleration and jerk features then test again.
Disabling relative features for now, will explore again if necessary.
Minimal initial gains from acceleration and jerk. Think the move forward is now EDA and feature selection.

Key Finding: Need to explore transformations (log, sqrt, square, etc.) to observe non-linear effects.
Key Finding: Need to investigate linear correlation and linear dependence (multicollinearity) of features.

Use VIF for multicollinearity, pearson correlation for linear correlation. Mutual information for non-linear correlation.
Ran a 2 combination size experiment with right hand velocity x mean as the required global feature.
Baseline performance by itself with lightgbm was -0.2488. 6 combinations broke -0.2 barrier.
These were:
    - RightHand_quat_x_mean
    - RightHand_quat_z_median (-0.179, best performer)
    - RightHand_quat_z_mean
    - RightHand_velocity_z_min
    - RightHand_jerk_z_min
    - Head_jerk_pause_duration_max

Exported new feature table (summary stats for all features on all participants) to csv at results/feature_exports/features_A.csv
Adding utils for scatter plot generation, correlation matrix, pearson correlation, VIF, and mutual information using the feature table.
Will analyze for linear/nonlinear correlation, multicollinearity, etc. as previously stated.
Initial analysis shows that there are some slight but apparent trends in features that are performing well.
However, the relationship is clearly not linear, so there multiple features will be necessary to account for the variance in the score.

Key Finding: Outliers need to be controlled for.
Key Finding: Noise in motion features might benefit from some form of filtering like smoothing.

Note: General rule is around sqrt(N) to N-1 features for small datasets. So 10-100 features is potentially acceptable.

Docket:
    - Time spent above threshold/below threshold for multiple features (velocity, etc)
    - Time spent in quadrant for position and euler
    - Examine and apply transformations
    - Aggregate features
    - Remove features with poor variance, correlation, and dependence

v4 (Version 4) [Hurdle Model]:
Applied boxcox transformations across the board; minimal gains and losses.
Clear that through simple transformations, combinations, and statistics, little performance can be gained.
Instead requires reframing of the problem, now taking a hurdle model approach.
The score has a high number of true 0s, so a hurdle model dichotomizes the score into 0 and non-0.
We train a binary classifier to predict whether the score is 0 or not, and then train a regression model to predict the score given that it is not 0.

So far, binary classification has yielded 0.904 accuracy for most velocity and quaternion features.
However, precision is around 0.8 for most features, so there is room for improvement.
RightHand_quat_y_mean and Head_quat_y_mean have slightly lower accuracy and recall (0.895), but higher precision and f1 score.
Around 1% higher than the rest in f1 score (0.8688 to 0.8595) but almost 4% higher in precision (0.857 to 0.819).
Low precision says that a participant will have a non-zero error rate when they will not, which of low consequence.
Of higher consequence is low recall, which says that a participant will have a zero error rate when they should not.
Will seek to improve the classifier before proceeding with the regression model.
This has been done with a lightgbm classifier, so other models still need to be explored as well.

"""The negative class (label 'Non-0') represents scores greater than 0
The positive class (label '0') represents scores of exactly 0
This means when interpreting metrics like precision, recall, and F1-score:
True Positives are correctly identified zero scores
True Negatives are correctly identified non-zero scores
False Positives are non-zero scores incorrectly classified as zero
False Negatives are zero scores incorrectly classified as non-zero"""

kNN: RightHand_quat_w_mean and Head_velocity_z_mean have 0.914 accuracy, 0.881 f1 score, 0.92 precision, and 0.914 recall.
tabPFN and SVM: uniform results, nothing outstanding. Maybe better with more features then?

Boxcox on hurdle model regressor score could reduce skew and improve performance.
Right hand velocity x median and A build time get 92% accuracy and 0.9086 f1 score.
More quat or velocity features though reduce these scores.
Really high mutual information from angular velocity and euler features, which makes sense but hasn't shown in the models.

Supervised PCA didn't provide any out-of-box improvements.
Neither did unsupervised PCA.


Body relative -> head is shifting origin (parent of transform)
Dominant hand relative -> Right hand is shifting origin (parent of transform)
Segment approach is not out of box best, but it does provide a way to get more data.
Need to review mutual information with the segment approach and 0 vs non-0.
Logistic regression with elastic net regularization is a good candidate for the hurdle model.
Maybe explore Hi/Lo rather than 0 vs non-0 (more data for each class)
Cross-validation should be checked out for within A, within segment
Update output of score from multiple of 2 to 1
Email ryan to ask for video and step data
Sliding window approach rather than fixed segment
Separate by object (head, controller)
Experiment with thresholds and modes for segmenting
Maybe prevent undersampling majority since already low number of samples
Experiment with other segment level features
Could position of segment in series be useful? (Start, middle , end)
Maybe number of segments is a feature
Consider pauses as opposed to velocity segments, and pause duration as a feature
Component (axis) level thresholding
Pos rotation etc for segment level features
Time series prediction as feature? predicting next segment or confidence of next segment as a feature (kind of like a PRM)

--------------------------------

Nested cross validation to prevent overfitting on noise
Use percent classified correctly for each class as performance heuristic rather than strictly roc auc or pr

Use LOOCV cross validation due to small dataset size
Embedded (linear model + regularization)
or Sequential with SVM or GBM
Balanced accuracy or f1 score as scoring objective due to class imbalance
Hyperparameter tuning for each fold
When all combined should be enough to prevent overfitting alongside domain knowledge of features

IMPORTANT: Use confidence of classifier prediction (predict_proba) to discern model quality. Also to use as input feature to regressor (probability the sample is perfect or not)
IMPORTANT: Ensemble left hand, right hand, head specific classifiers/regressors? (Only given features for each object, majority voting of all 3 models used).

Most common advice is to use domain knowledge. With small dataset bound to overfit if too many features, so hand pick those that make sense

Verify representations of body and head
Comparison of representations