# H2 Abstract
In recent years, virtual reality (VR) has seen a strong increase in popularity for training and simulation. These simulations produce data useful for evaluating user performance. Prior works have focused on analyzing and predicting the correlation of training data with a measurable outcome in exclusively virtual or real-world contexts. In this paper, we present the first systematic investigation of how combinations of kinematic (position, velocity, acceleration, and jerk) and spatial (linear or rotational) representations affect classification accuracy of skill transfer from virtual to real-world contexts. We utilize an open-source assembly dataset to achieve this, training on users' virtual tutorial motion data to predict their real-world performance. Our results indicate that a combination of velocity and jerk features performs best, affirming context-specific findings from prior works. The results also show that a combination of both linear and angular features yields higher performance.

# H2 Introduction
Recently, a number of works have examined...(Buildup)
In this paper, we present the first systematic investigation of how combinations of kinematic (position, velocity, acceleration, and jerk) and spatial (linear or rotational) representations affect the classification accuracy of user performance across contexts, for two unique tasks in the assembly domain. To conduct our experiments, we utilize the Full-scale Assembly Simulation Testbed (FAST) which provides both user motion data from virtual training sessions for two assembly tasks, and a score evaluating their performance on the real-world counterparts for each of those tasks. This dataset was used to conduct two studies, investigating the various